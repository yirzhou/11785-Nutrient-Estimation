{"cells":[{"cell_type":"markdown","metadata":{"id":"D-QNNGMCMTY3"},"source":["# Midterm Expectation\n","\n","- Baseline\n","- Experiment (i.e., something different; e.x., spreadsheet)\n","- Timeline (what we have done, and what we will be doing)"]},{"cell_type":"markdown","metadata":{"id":"5NXFw1rhMTY7"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"LnnqK5WMMTY7","executionInfo":{"status":"ok","timestamp":1651268218918,"user_tz":420,"elapsed":1073,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision.transforms import (\n","    CenterCrop,\n","    Compose,\n","    RandAugment,\n","    RandomPerspective,\n","    RandomHorizontalFlip,\n","    RandomRotation,\n","    ToTensor,\n",")\n","from PIL import Image\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm import tqdm\n","import math"]},{"cell_type":"markdown","metadata":{"id":"msbOJn4yNcIq"},"source":["# Mount Google Drive"]},{"cell_type":"markdown","source":["## Install gdfuse"],"metadata":{"id":"H4N---LU7A6W"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MAcPoTN7NgAZ","outputId":"49c8a629-172f-4238-e55a-c5ea61b72d10","executionInfo":{"status":"ok","timestamp":1651268227454,"user_tz":420,"elapsed":8538,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n","\n"]}],"source":["!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!sudo apt-get update -qq 2>&1 > /dev/null\n","!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n","!google-drive-ocamlfuse"]},{"cell_type":"markdown","source":["## Fetch API Key"],"metadata":{"id":"BnF7W4O37EPg"}},{"cell_type":"code","source":["!sudo apt-get install -qq w3m # to act as web browser \n","!xdg-settings set default-web-browser w3m.desktop # to set default browser\n","%cd /content\n","!mkdir drive\n","%cd drive\n","!mkdir MyDrive\n","%cd ..\n","%cd ..\n","!google-drive-ocamlfuse /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3TUxRDhD7GTk","outputId":"b7172ea3-989f-4fc5-b2a8-1119e1d26f0e","executionInfo":{"status":"ok","timestamp":1651268232967,"user_tz":420,"elapsed":5529,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","mkdir: cannot create directory ‘drive’: File exists\n","/content/drive\n","mkdir: cannot create directory ‘MyDrive’: File exists\n","/content\n","/\n","fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n"]}]},{"cell_type":"markdown","metadata":{"id":"28paTv3yY-E6"},"source":["# Unzip Data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gm5chDQyZBLO","executionInfo":{"status":"ok","timestamp":1651268232968,"user_tz":420,"elapsed":24,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["# ! pip install gdown\n","# ! cd /content/ && gdown https://drive.google.com/uc?id=1zD7fUAt12L16ywPSjRsj4IqL-Lqg13zK\n","# # ! cp /content/drive/MyDrive/11785/project/data.zip /content/\n","# ! cd /content && unzip data.zip\n","# ! rm /content/data.zip"]},{"cell_type":"markdown","metadata":{"id":"n59ANLHGMTY9"},"source":["# Global Variables"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dJdqOG31MTY9","executionInfo":{"status":"ok","timestamp":1651268232969,"user_tz":420,"elapsed":24,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["DATA_PATH = \"/content/data\"\n","METADATA_DIR = f\"{DATA_PATH}/metadata\"\n","IMAGERY_DIR = f\"{DATA_PATH}/imagery/realsense_overhead\""]},{"cell_type":"markdown","metadata":{"id":"EKfNoKuIMTY9"},"source":["# Helper Functions for Data"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Lbs8y5P5MTY-","executionInfo":{"status":"ok","timestamp":1651268232969,"user_tz":420,"elapsed":23,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["def read_csv_variable_cols(filepath: str) -> pd.DataFrame:\n","    \"\"\"https://stackoverflow.com/a/57824142.\n","    We only read the first 6 columns to retrieve required labels.\n","    \"\"\"\n","    ### Loop the data lines\n","    with open(filepath, 'r') as temp_f:\n","        # get No of columns in each line\n","        col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n","\n","    ### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\n","    column_names = [i for i in range(0, max(col_count))]\n","\n","    ### Read csv\n","    return pd.read_csv(filepath, header=None, delimiter=\",\", names=column_names, low_memory=False).iloc[:,:6]"]},{"cell_type":"markdown","metadata":{"id":"L461g1bEMTY_"},"source":["# Ingredient and Dish Metadata (Groun Truths)"]},{"cell_type":"markdown","metadata":{"id":"TD2SzXIYMTY_"},"source":["## Data Format\n","\n","### Training-testing data\n","\n","- \"imagery/realsense_overhead/dish_<id>\" contains the images as the input data\n","- \"dish_ids\" contains training-testing splits\n","\n","### Labels (metadata)\n","\n","All labels need to be preprocessed. For each dish, we need to extract the following:\n","- total calorie\n","- mass (optional according to the paper)\n","- the amount of the three macronutrients (fat, carb, protein)\n","\n","It doesn't seem that bad - we don't need to process the ingredients because they are purely there for constructing the labels. For our multi-task learning, we only need to have the above labels. The three tasks are:\n","\n","1. Calorie\n","2. Macronutrients (fat, carb, protein)\n","3. Mass (optional)\n","\n","这样一来我们可以把labels和image data放在一起，每次返回input和expected output."]},{"cell_type":"markdown","metadata":{"id":"HxLtWU6WMTZA"},"source":["## Dish Metadata"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"cV6hUYHiMTZA","executionInfo":{"status":"ok","timestamp":1651268232970,"user_tz":420,"elapsed":24,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["# Metadata for dishes has variable numbers of columns per row.\n","# Can do similar stuff to dish_metadata_cafe2.csv\n","# The first 6 columns: [dish_id, total_calories, total_mass, total_fat, total_carb, total_protein]\n","dish_metadata_1 = read_csv_variable_cols(f\"{METADATA_DIR}/dish_metadata_cafe1.csv\")\n","# Rename the columns\n","dish_metadata_1 = dish_metadata_1.rename(columns={0:\"dish_id\", 1:\"total_calories\", 2:\"total_mass\", 3:\"total_fat\", 4:\"total_carb\", 5:\"total_protein\"})\n","\n","dish_metadata_2 = read_csv_variable_cols(f\"{METADATA_DIR}/dish_metadata_cafe2.csv\")\n","# Rename the columns\n","dish_metadata_2 = dish_metadata_2.rename(columns={0:\"dish_id\", 1:\"total_calories\", 2:\"total_mass\", 3:\"total_fat\", 4:\"total_carb\", 5:\"total_protein\"})\n","\n","dish_metadata = pd.concat((dish_metadata_1, dish_metadata_2), ignore_index=True)\n","# Convert to dictionary\n","labels_dict = dish_metadata.set_index(\"dish_id\").to_dict(\"index\")"]},{"cell_type":"markdown","metadata":{"id":"65hoT-vkMTZB"},"source":["# Hyperparameters"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1WszLEHvMTZB","executionInfo":{"status":"ok","timestamp":1651268232971,"user_tz":420,"elapsed":25,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["config = {\n","    'epochs': 150,\n","    'batch_size': 32,\n","    'lr': 2e-4,\n","}\n","\n","class Config:\n","    def __init__(self, config):\n","        for k, v in config.items():\n","            setattr(self, k, v)\n","\n","config = Config(config)"]},{"cell_type":"markdown","metadata":{"id":"gePyzvWIMTZB"},"source":["# Datasets and DataLoaders"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"gYM_uPdMMTZC","executionInfo":{"status":"ok","timestamp":1651268232972,"user_tz":420,"elapsed":25,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["transforms_augmented = Compose([CenterCrop((256, 256)), RandAugment(3), RandomHorizontalFlip(), ToTensor()])\n","transforms_default = Compose([CenterCrop((256, 256)), ToTensor()])\n","transforms = Compose([CenterCrop((256, 256)), RandomPerspective(), RandomHorizontalFlip(), ToTensor()])\n","class RGBDataset(Dataset):\n","    \"\"\"4.2 The input resolution to the\n","    network is a 256x256 image, where images were downsized\n","    and center cropped in order to retain the most salient dish\n","    region.\n","\n","    我们baseline应该只用RGB就行 (根据4.2).\n","    \"\"\"\n","\n","    def __init__(self, data_dir, transforms=transforms_default, labels=labels_dict, train=True):\n","        self.data_dir = data_dir\n","        self.transforms = transforms\n","        self.labels = labels\n","        self.train = train\n","\n","        # # ['dish_1556572657', 'dish_1556573514', 'dish_1556575014', 'dish_1556575083', 'dish_1556575124', 'dish_1556575273', 'dish_1556575327']\n","        dirs = os.listdir(self.data_dir)\n","\n","        self.dish_ids = []\n","        for dir in dirs:\n","            if \"rgb.png\" in os.listdir(os.path.join(self.data_dir,dir)):\n","                self.dish_ids.append(dir)\n","\n","        self.dish_ids.sort()\n","\n","        self.img_paths = list(\n","            map(\n","                lambda fname: os.path.join(self.data_dir, fname),\n","                self.dish_ids,\n","            )\n","        )\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        rgb_path = f\"{self.img_paths[idx]}/rgb.png\"\n","        dish_id = self.dish_ids[idx]\n","        transformed_img = self.transforms(Image.open(rgb_path))\n","        if self.train:\n","            label = torch.tensor(list(self.labels[dish_id].values()))\n","            return transformed_img, label\n","        else:\n","            return transformed_img"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"zDzPOZPxMTZC","executionInfo":{"status":"ok","timestamp":1651268233340,"user_tz":420,"elapsed":393,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["TRAIN_DIR = f\"{IMAGERY_DIR}/train\"\n","VALID_DIR = f\"{IMAGERY_DIR}/test\"\n","# TEST_DIR = IMAGERY_DIR\n","\n","train_dataset = RGBDataset(TRAIN_DIR, labels=labels_dict)\n","valid_dataset = RGBDataset(VALID_DIR, labels=labels_dict)\n","# test_dataset = RGBDataset(TEST_DIR, train=False)\n","\n","train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n","valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n","# test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n","\n","num_training_batches = len(train_loader)"]},{"cell_type":"markdown","metadata":{"id":"5pAxIycIMTZD"},"source":["# InceptionV2"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"jIkDGyD2MTZD","executionInfo":{"status":"ok","timestamp":1651268233341,"user_tz":420,"elapsed":7,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["def ConvBNReLU(in_channels,out_channels,kernel_size,stride=1,padding=0):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,padding=padding),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU6(inplace=True),\n","    )\n","\n","def ConvBNReLUFactorization(in_channels,out_channels,kernel_sizes,paddings):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_sizes, stride=1,padding=paddings),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU6(inplace=True)\n","    )\n","\n","class InceptionV2ModuleA(nn.Module):\n","    def __init__(self, in_channels,out_channels1,out_channels2reduce, out_channels2, out_channels3reduce, out_channels3, out_channels4):\n","        super(InceptionV2ModuleA, self).__init__()\n","\n","        self.branch1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=1)\n","\n","        self.branch2 = nn.Sequential(\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1),\n","            ConvBNReLU(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_size=3, padding=1),\n","        )\n","\n","        self.branch3 = nn.Sequential(\n","            ConvBNReLU(in_channels=in_channels,out_channels=out_channels3reduce,kernel_size=1),\n","            ConvBNReLU(in_channels=out_channels3reduce, out_channels=out_channels3, kernel_size=3, padding=1),\n","            ConvBNReLU(in_channels=out_channels3, out_channels=out_channels3, kernel_size=3, padding=1),\n","        )\n","\n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n","        )\n","\n","    def forward(self, x):\n","        out1 = self.branch1(x)\n","        out2 = self.branch2(x)\n","        out3 = self.branch3(x)\n","        out4 = self.branch4(x)\n","        out = torch.cat([out1, out2, out3, out4], dim=1)\n","        return out\n","\n","class InceptionV2ModuleB(nn.Module):\n","    def __init__(self, in_channels,out_channels1,out_channels2reduce, out_channels2, out_channels3reduce, out_channels3, out_channels4):\n","        super(InceptionV2ModuleB, self).__init__()\n","\n","        self.branch1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=1)\n","\n","        self.branch2 = nn.Sequential(\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1),\n","            ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2reduce, kernel_sizes=[1,3],paddings=[0,1]),\n","            ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_sizes=[3,1],paddings=[1, 0]),\n","        )\n","\n","        self.branch3 = nn.Sequential(\n","            ConvBNReLU(in_channels=in_channels,out_channels=out_channels3reduce,kernel_size=1),\n","            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3reduce,kernel_sizes=[1, 3], paddings=[0, 1]),\n","            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3reduce,kernel_sizes=[3, 1], paddings=[1, 0]),\n","            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3reduce, kernel_sizes=[1, 3], paddings=[0, 1]),\n","            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3,kernel_sizes=[3, 1], paddings=[1, 0]),\n","        )\n","\n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n","        )\n","\n","    def forward(self, x):\n","        out1 = self.branch1(x)\n","        out2 = self.branch2(x)\n","        out3 = self.branch3(x)\n","        out4 = self.branch4(x)\n","        out = torch.cat([out1, out2, out3, out4], dim=1)\n","        return out\n","\n","class InceptionV2ModuleC(nn.Module):\n","    def __init__(self, in_channels,out_channels1,out_channels2reduce, out_channels2, out_channels3reduce, out_channels3, out_channels4):\n","        super(InceptionV2ModuleC, self).__init__()\n","\n","        self.branch1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=1)\n","\n","        self.branch2_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1)\n","        self.branch2_conv2a = ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_sizes=[1,3],paddings=[0,1])\n","        self.branch2_conv2b = ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_sizes=[3,1],paddings=[1,0])\n","\n","        self.branch3_conv1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels3reduce,kernel_size=1)\n","        self.branch3_conv2 = ConvBNReLU(in_channels=out_channels3reduce, out_channels=out_channels3, kernel_size=3,stride=1,padding=1)\n","        self.branch3_conv3a = ConvBNReLUFactorization(in_channels=out_channels3, out_channels=out_channels3, kernel_sizes=[3, 1],paddings=[1, 0])\n","        self.branch3_conv3b = ConvBNReLUFactorization(in_channels=out_channels3, out_channels=out_channels3, kernel_sizes=[1, 3],paddings=[0, 1])\n","\n","        self.branch4 = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n","        )\n","\n","    def forward(self, x):\n","        out1 = self.branch1(x)\n","        x2 = self.branch2_conv1(x)\n","        out2 = torch.cat([self.branch2_conv2a(x2), self.branch2_conv2b(x2)],dim=1)\n","        x3 = self.branch3_conv2(self.branch3_conv1(x))\n","        out3 = torch.cat([self.branch3_conv3a(x3), self.branch3_conv3b(x3)], dim=1)\n","        out4 = self.branch4(x)\n","        out = torch.cat([out1, out2, out3, out4], dim=1)\n","        return out\n","\n","class InceptionV3ModuleD(nn.Module):\n","    def __init__(self, in_channels,out_channels1reduce,out_channels1,out_channels2reduce, out_channels2):\n","        super(InceptionV3ModuleD, self).__init__()\n","\n","        self.branch1 = nn.Sequential(\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels1reduce, kernel_size=1),\n","            ConvBNReLU(in_channels=out_channels1reduce, out_channels=out_channels1, kernel_size=3,stride=2,padding=1)\n","        )\n","\n","        self.branch2 = nn.Sequential(\n","            ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1),\n","            ConvBNReLU(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_size=3, stride=1, padding=1),\n","            ConvBNReLU(in_channels=out_channels2, out_channels=out_channels2, kernel_size=3, stride=2,padding=1),\n","        )\n","\n","        self.branch3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n","\n","    def forward(self, x):\n","        out1 = self.branch1(x)\n","        out2 = self.branch2(x)\n","        out3 = self.branch3(x)\n","        out = torch.cat([out1, out2, out3], dim=1)\n","        return out\n","\n","class InceptionAux(nn.Module):\n","    def __init__(self, in_channels,out_channels):\n","        super(InceptionAux, self).__init__()\n","\n","        self.auxiliary_avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n","        self.auxiliary_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=128, kernel_size=1)\n","        self.auxiliary_conv2 = nn.Conv2d(in_channels=128, out_channels=768, kernel_size=5,stride=1)\n","        self.auxiliary_dropout = nn.Dropout(p=0.7)\n","        self.auxiliary_linear1 = nn.Linear(in_features=768, out_features=out_channels)\n","\n","    def forward(self, x):\n","        x = self.auxiliary_conv1(self.auxiliary_avgpool(x))\n","        x = self.auxiliary_conv2(x)\n","        x = x.view(x.size(0), -1)\n","        out = self.auxiliary_linear1(self.auxiliary_dropout(x))\n","        return out\n","\n","class InceptionV2(nn.Module):\n","    def __init__(self, num_classes=1000, stage='train'):\n","        super(InceptionV2, self).__init__()\n","        self.stage = stage\n","\n","        self.block1 = nn.Sequential(\n","            ConvBNReLU(in_channels=3, out_channels=64, kernel_size=7,stride=2,padding=3),\n","            nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n","        )\n","\n","        self.block2 = nn.Sequential(\n","            ConvBNReLU(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1),\n","            nn.MaxPool2d(kernel_size=3, stride=2,padding=1),\n","        )\n","\n","        self.block3 = nn.Sequential(\n","            InceptionV2ModuleA(in_channels=192,out_channels1=64,out_channels2reduce=64, out_channels2=64, out_channels3reduce=64, out_channels3=96, out_channels4=32),\n","            InceptionV2ModuleA(in_channels=256, out_channels1=64, out_channels2reduce=64, out_channels2=96,out_channels3reduce=64, out_channels3=96, out_channels4=64),\n","            InceptionV3ModuleD(in_channels=320, out_channels1reduce=128, out_channels1=160, out_channels2reduce=64,out_channels2=96),\n","        )\n","\n","        self.block4 = nn.Sequential(\n","            InceptionV2ModuleB(in_channels=576, out_channels1=224, out_channels2reduce=64, out_channels2=96,out_channels3reduce=96, out_channels3=128, out_channels4=128),\n","            InceptionV2ModuleB(in_channels=576, out_channels1=192, out_channels2reduce=96, out_channels2=128,out_channels3reduce=96, out_channels3=128, out_channels4=128),\n","            InceptionV2ModuleB(in_channels=576, out_channels1=160, out_channels2reduce=128, out_channels2=160,out_channels3reduce=128, out_channels3=128, out_channels4=128),\n","            InceptionV2ModuleB(in_channels=576, out_channels1=96, out_channels2reduce=128, out_channels2=192,out_channels3reduce=160, out_channels3=160, out_channels4=128),\n","            InceptionV3ModuleD(in_channels=576, out_channels1reduce=128, out_channels1=192, out_channels2reduce=192,out_channels2=256),\n","        )\n","\n","        self.block5 = nn.Sequential(\n","            InceptionV2ModuleC(in_channels=1024, out_channels1=352, out_channels2reduce=192, out_channels2=160,out_channels3reduce=160, out_channels3=112, out_channels4=128),\n","            InceptionV2ModuleC(in_channels=1024, out_channels1=352, out_channels2reduce=192, out_channels2=160,\n","                               out_channels3reduce=192, out_channels3=112, out_channels4=128)\n","        )\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d((2,2))\n","        self.dropout = nn.Dropout(p=0.5)\n","    \n","\n","    def forward(self, x):\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        x = self.block4(x)\n","        x = self.block5(x)\n","        x = self.avg_pool(x)\n","        x = self.dropout(x)\n","        x = x.view(x.size(0), -1)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"U8khcs7eeugO"},"source":["# Resnets"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"YvKzmQ-Cep_U","executionInfo":{"status":"ok","timestamp":1651268233342,"user_tz":420,"elapsed":7,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["import torch.utils.model_zoo as model_zoo\n","resnet_model_urls = {\n","    'resnet18': 'https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth',\n","    'resnet34': 'https://s3.amazonaws.com/pytorch/models/resnet34-333f7ec4.pth',\n","    'resnet50': 'https://s3.amazonaws.com/pytorch/models/resnet50-19c8e357.pth',\n","    'resnet101': 'https://s3.amazonaws.com/pytorch/models/resnet101-5d3b4d8f.pth',\n","    'resnet152': 'https://s3.amazonaws.com/pytorch/models/resnet152-b121ed2d.pth',\n","}\n","\n","class Bottleneck(nn.Module):\n","  expansion = 4\n","\n","  def __init__(self, inplanes, planes, stride=1, downsample=None):\n","    super(Bottleneck, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n","    self.bn1 = nn.BatchNorm2d(planes)\n","    \n","    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n","                 padding=1, bias=False)\n","    self.bn2 = nn.BatchNorm2d(planes)\n","    \n","    self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","    self.bn3 = nn.BatchNorm2d(planes * 4)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.downsample = downsample\n","    self.stride = stride\n","\n","  def forward(self, x):\n","    residual = x\n","\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu(out)\n","\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    out = self.relu(out)\n","\n","    out = self.conv3(out)\n","    out = self.bn3(out)\n","\n","    if self.downsample is not None:\n","      residual = self.downsample(x)\n","\n","    out += residual\n","    out = self.relu(out)\n","\n","    return out\n","    \n","    \n","class ResNet(nn.Module):\n","  def __init__(self, block, layers, num_classes=1000):\n","    self.inplanes = 64\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                 bias=False)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, ceil_mode=True) # change\n","    self.layer1 = self._make_layer(block, 64, layers[0])\n","    self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","    self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","    self.layer4 = self._make_layer(block, 512, layers[3], stride=2)   # different\n","    self.avgpool = nn.AvgPool2d(7)\n","    self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","        m.weight.data.normal_(0, math.sqrt(2. / n))\n","      elif isinstance(m, nn.BatchNorm2d):\n","        m.weight.data.fill_(1)\n","        m.bias.data.zero_()\n","\n","  def _make_layer(self, block, planes, blocks, stride=1):\n","    downsample = None\n","    if stride != 1 or self.inplanes != planes * block.expansion:\n","      downsample = nn.Sequential(\n","        nn.Conv2d(self.inplanes, planes * block.expansion,\n","              kernel_size=1, stride=stride, bias=False),\n","        nn.BatchNorm2d(planes * block.expansion),\n","      )\n","\n","    layers = []\n","    layers.append(block(self.inplanes, planes, stride, downsample))\n","    self.inplanes = planes * block.expansion\n","    for i in range(1, blocks):\n","      layers.append(block(self.inplanes, planes))\n","\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.maxpool(x)\n","\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","\n","    x = self.avgpool(x)\n","    x = x.view(x.size(0), -1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","def resnet50(pretrained=True):\n","  \"\"\"Constructs a ResNet-50 model.\n","  Args:\n","    pretrained (bool): If True, returns a model pre-trained on ImageNet\n","  \"\"\"\n","  model = ResNet(Bottleneck, [3, 4, 6, 3])\n","  if pretrained:\n","    model.load_state_dict(model_zoo.load_url(resnet_model_urls['resnet50']))\n","  return model\n","\n","def resnet101(pretrained=True):\n","  \"\"\"Constructs a ResNet-50 model.\n","  Args:\n","    pretrained (bool): If True, returns a model pre-trained on ImageNet\n","  \"\"\"\n","  model = ResNet(Bottleneck, [3, 4, 23, 3])\n","  if pretrained:\n","    model.load_state_dict(model_zoo.load_url(resnet_model_urls['resnet101']))\n","  return model\n","\n","\n","def resnet152(pretrained=True):\n","  \"\"\"Constructs a ResNet-152 model.\n","  Args:\n","    pretrained (bool): If True, returns a model pre-trained on ImageNet\n","  \"\"\"\n","  model = ResNet(Bottleneck, [3, 8, 36, 3])\n","  if pretrained:\n","    model.load_state_dict(model_zoo.load_url(resnet_model_urls['resnet152']))\n","  return model"]},{"cell_type":"markdown","source":["# ConvNext"],"metadata":{"id":"BR4hSKp6RiFz"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","def truncated_normal_(tensor, mean=0, std=0.09):\n","    with torch.no_grad():\n","        size = tensor.shape\n","        tmp = tensor.new_empty(size + (4,)).normal_()\n","        valid = (tmp < 2) & (tmp > -2)\n","        ind = valid.max(-1, keepdim=True)[1]\n","        tensor.data.copy_(tmp.gather(-1, ind).squeeze(-1))\n","        tensor.data.mul_(std).add_(mean)\n","        return tensor\n","\n","\n","class ConvNeXtBlock(nn.Module):\n","    \"\"\" The architecture of this block is as follows :\n","    \n","    DepthWise conv -> Permute to (N, H, W, C); [Channel Last]; Layer_norm -> Linear -> GELU -> Linear -> Permute Back\n","\n","    Channel Last is used in input dimensions because its faster in PyTorch\n","    \n","    \"\"\"\n","\n","    def __init__(\n","        self, in_channel, depth_rate=0.0, layer_scale_init_value=1e-6\n","    ):\n","        super(ConvNeXtBlock, self).__init__()\n","\n","        \"\"\"Using Group covolution using groups as in the in_channel so it behaves as Depth Wise Convolution\"\"\"\n","        self.depthWiseConv = nn.Conv2d(\n","            in_channel, in_channel, kernel_size=7, padding=3, groups=in_channel\n","        )\n","\n","        self.norm = Layer_norm(in_channel, eps=1e-6)\n","\n","        \"\"\"point wise convolution with 1x1 conv is similar to a Linear Layer\"\"\"\n","        self.pointWiseConv1 = nn.Linear(in_channel, 4 * in_channel)\n","\n","        self.activation = nn.GELU()\n","\n","        self.pointWiseConv2 = nn.Linear(4 * in_channel, in_channel)\n","\n","        self.gamma = (\n","            nn.Parameter(\n","                layer_scale_init_value * torch.ones((in_channel)),\n","                requires_grad=True,\n","            )\n","            if layer_scale_init_value > 0\n","            else None\n","        )\n","\n","        \"\"\"Stochastic Depth aims to shrink the depth of a network during training, \n","        while keeping it unchanged during testing. This is achieved by randomly dropping \n","        entire ResBlocks during training and bypassing their transformations through \n","        skip connections.\"\"\"\n","        self.dropPath = nn.Identity()\n","\n","    def forward(self, x):\n","        in_tensor = x\n","        x = self.depthWiseConv(x)\n","        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n","        x = self.norm(x)\n","        x = self.pointWiseConv1(x)\n","        x = self.activation(x)\n","        x = self.pointWiseConv2(x)\n","        if self.gamma is not None:\n","            x = self.gamma * x\n","        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n","\n","        x = in_tensor + self.dropPath(x)\n","\n","        return x\n","\n","\n","class Layer_norm(nn.Module):\n","    def __init__(self, normShape, eps=1e-6, input_format=\"Channel_Last\"):\n","        super(Layer_norm, self).__init__()\n","        self.weight = nn.Parameter(torch.ones(normShape))\n","        self.bias = nn.Parameter(torch.zeros(normShape))\n","        self.eps = eps\n","        self.dataFormat = input_format\n","        if self.dataFormat not in [\"Channel_Last\", \"Channel_First\"]:\n","            raise NotImplementedError\n","        self.normShape = (normShape,)\n","\n","    def forward(self, x):\n","        if self.dataFormat == \"Channel_Last\":\n","            return F.layer_norm(\n","                x, self.normShape, self.weight, self.bias, self.eps\n","            )\n","        elif self.dataFormat == \"Channel_First\":\n","            u = x.mean(1, keepdim=True)\n","            s = (x - u).pow(2).mean(1, keepdim=True)\n","            x = (x - u) / torch.sqrt(s + self.eps)\n","            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n","            return x\n","\n","\n","class ConvNeXt(nn.Module):\n","    \"\"\"\n","    Args:\n","        in_channels (int): Number of input image channels. Default: 3\n","        num_classes (int): Number of classes for classification head. Default: 100\n","        depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n","        dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n","        drop_path_rate (float): Stochastic depth rate. Default: 0.\n","        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n","        head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n","    \n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        in_channels=3,\n","        num_classes=1000,\n","        depths=[3, 3, 9, 3],\n","        dims=[96, 192, 384, 768],\n","        drop_path_rate=0.0,\n","        layer_scale_init_value=1e-6,\n","        head_init_scale=1.0,\n","    ):\n","\n","        super(ConvNeXt, self).__init__()\n","\n","        self.downsample_layers = nn.ModuleList()\n","        stem = nn.Sequential(\n","            nn.Conv2d(in_channels, dims[0], kernel_size=4, stride=4),\n","            Layer_norm(dims[0], eps=1e-6, input_format=\"Channel_First\"),\n","        )\n","        self.downsample_layers.append(stem)\n","\n","        for i in range(3):\n","            downsample_layer = nn.Sequential(\n","                Layer_norm(dims[i], eps=1e-6, input_format=\"Channel_First\"),\n","                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n","            )\n","            self.downsample_layers.append(downsample_layer)\n","\n","        self.stages = nn.ModuleList()\n","        dp_rates = [x for x in torch.linspace(0, drop_path_rate, sum(depths))]\n","        cur = 0\n","\n","        for i in range(4):\n","            stage = nn.Sequential(\n","                *[\n","                    ConvNeXtBlock(\n","                        in_channel=dims[i],\n","                        depth_rate=dp_rates[cur + j],\n","                        layer_scale_init_value=layer_scale_init_value,\n","                    )\n","                    for j in range(depths[i])\n","                ]\n","            )\n","\n","            self.stages.append(stage)\n","            cur += depths[i]\n","\n","        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)\n","        self.head = nn.Linear(dims[-1], num_classes)\n","\n","        self.apply(self.init_weights)\n","        self.head.weight.data.mul_(head_init_scale)\n","        self.head.bias.data.mul_(head_init_scale)\n","\n","    def init_weights(self, m):\n","        if isinstance(m, (nn.Conv2d, nn.Linear)):\n","            truncated_normal_(m.weight, std=0.02)\n","            nn.init.constant_(m.bias, 0)\n","\n","    def forward_stages(self, x):\n","        for i in range(4):\n","            x = self.downsample_layers[i](x)\n","            x = self.stages[i](x)\n","        return self.norm(\n","            x.mean([-2, -1])\n","        )  # global average pooling, (N, C, H, W) -> (N, C)\n","\n","    def forward(self, x, return_feats=False):\n","        x = self.forward_stages(x)\n","        if return_feats is True:\n","            return x\n","        x = self.head(x)\n","\n","        return x\n","\n","\n","def convnext_tiny(**kwargs):\n","    model = ConvNeXt(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], **kwargs)\n","    return model\n","\n","\n","def convnext_small(**kwargs):\n","    model = ConvNeXt(depths=[3, 3, 27, 3], dims=[96, 192, 384, 768], **kwargs)\n","    return model\n","\n","\n","def convnext_base(**kwargs):\n","    model = ConvNeXt(\n","        depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024], **kwargs\n","    )\n","    return model"],"metadata":{"id":"YX5GTL6jRkvw","executionInfo":{"status":"ok","timestamp":1651268233624,"user_tz":420,"elapsed":6,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# MobileNetV3"],"metadata":{"id":"magQzDMjnTgB"}},{"cell_type":"code","source":["import warnings\n","from functools import partial\n","from typing import Any, Callable, List, Optional, Sequence\n","\n","import torch\n","from torch import Tensor, nn\n","from torchvision.ops.misc import ConvNormActivation\n","from torchvision.ops.misc import SqueezeExcitation as SElayer\n","from torch.hub import load_state_dict_from_url\n","\n","__all__ = [\"MobileNetV3\", \"mobilenet_v3_large\", \"mobilenet_v3_small\"]\n","\n","\n","mobilnet_model_urls = {\n","    \"mobilenet_v3_large\": \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\",\n","    \"mobilenet_v3_small\": \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\",\n","}\n","\n","\n","def _make_divisible(\n","    v: float, divisor: int, min_value: Optional[int] = None\n",") -> int:\n","    \"\"\"\n","    This function is taken from the original tf repo.\n","    It ensures that all layers have a channel number that is divisible by 8\n","    It can be seen here:\n","    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n","    \"\"\"\n","    if min_value is None:\n","        min_value = divisor\n","    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n","    # Make sure that round down does not go down by more than 10%.\n","    if new_v < 0.9 * v:\n","        new_v += divisor\n","    return new_v\n","\n","\n","class SqueezeExcitation(SElayer):\n","    \"\"\"DEPRECATED\n","    \"\"\"\n","\n","    def __init__(self, input_channels: int, squeeze_factor: int = 4):\n","        squeeze_channels = _make_divisible(input_channels // squeeze_factor, 8)\n","        super().__init__(\n","            input_channels, squeeze_channels, scale_activation=nn.Hardsigmoid\n","        )\n","        self.relu = self.activation\n","        delattr(self, \"activation\")\n","        warnings.warn(\n","            \"This SqueezeExcitation class is deprecated and will be removed in future versions. \"\n","            \"Use torchvision.ops.misc.SqueezeExcitation instead.\",\n","            FutureWarning,\n","        )\n","\n","\n","class InvertedResidualConfig:\n","    # Stores information listed at Tables 1 and 2 of the MobileNetV3 paper\n","    def __init__(\n","        self,\n","        input_channels: int,\n","        kernel: int,\n","        expanded_channels: int,\n","        out_channels: int,\n","        use_se: bool,\n","        activation: str,\n","        stride: int,\n","        dilation: int,\n","        width_mult: float,\n","    ):\n","        self.input_channels = self.adjust_channels(input_channels, width_mult)\n","        self.kernel = kernel\n","        self.expanded_channels = self.adjust_channels(\n","            expanded_channels, width_mult\n","        )\n","        self.out_channels = self.adjust_channels(out_channels, width_mult)\n","        self.use_se = use_se\n","        self.use_hs = activation == \"HS\"\n","        self.stride = stride\n","        self.dilation = dilation\n","\n","    @staticmethod\n","    def adjust_channels(channels: int, width_mult: float):\n","        return _make_divisible(channels * width_mult, 8)\n","\n","\n","class InvertedResidual(nn.Module):\n","    # Implemented as described at section 5 of MobileNetV3 paper\n","    def __init__(\n","        self,\n","        cnf: InvertedResidualConfig,\n","        norm_layer: Callable[..., nn.Module],\n","        se_layer: Callable[..., nn.Module] = partial(\n","            SElayer, scale_activation=nn.Hardsigmoid\n","        ),\n","    ):\n","        super().__init__()\n","        if not (1 <= cnf.stride <= 2):\n","            raise ValueError(\"illegal stride value\")\n","\n","        self.use_res_connect = (\n","            cnf.stride == 1 and cnf.input_channels == cnf.out_channels\n","        )\n","\n","        layers: List[nn.Module] = []\n","        activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU\n","\n","        # expand\n","        if cnf.expanded_channels != cnf.input_channels:\n","            layers.append(\n","                ConvNormActivation(\n","                    cnf.input_channels,\n","                    cnf.expanded_channels,\n","                    kernel_size=1,\n","                    norm_layer=norm_layer,\n","                    activation_layer=activation_layer,\n","                )\n","            )\n","\n","        # depthwise\n","        stride = 1 if cnf.dilation > 1 else cnf.stride\n","        layers.append(\n","            ConvNormActivation(\n","                cnf.expanded_channels,\n","                cnf.expanded_channels,\n","                kernel_size=cnf.kernel,\n","                stride=stride,\n","                dilation=cnf.dilation,\n","                groups=cnf.expanded_channels,\n","                norm_layer=norm_layer,\n","                activation_layer=activation_layer,\n","            )\n","        )\n","        if cnf.use_se:\n","            squeeze_channels = _make_divisible(cnf.expanded_channels // 4, 8)\n","            layers.append(se_layer(cnf.expanded_channels, squeeze_channels))\n","\n","        # project\n","        layers.append(\n","            ConvNormActivation(\n","                cnf.expanded_channels,\n","                cnf.out_channels,\n","                kernel_size=1,\n","                norm_layer=norm_layer,\n","                activation_layer=None,\n","            )\n","        )\n","\n","        self.block = nn.Sequential(*layers)\n","        self.out_channels = cnf.out_channels\n","        self._is_cn = cnf.stride > 1\n","\n","    def forward(self, input: Tensor) -> Tensor:\n","        result = self.block(input)\n","        if self.use_res_connect:\n","            result += input\n","        return result\n","\n","\n","class MobileNetV3(nn.Module):\n","    def __init__(\n","        self,\n","        inverted_residual_setting: List[InvertedResidualConfig],\n","        last_channel: int,\n","        num_classes: int = 1000,\n","        block: Optional[Callable[..., nn.Module]] = None,\n","        norm_layer: Optional[Callable[..., nn.Module]] = None,\n","        **kwargs: Any\n","    ) -> None:\n","        \"\"\"\n","        MobileNet V3 main class\n","\n","        Args:\n","            inverted_residual_setting (List[InvertedResidualConfig]): Network structure\n","            last_channel (int): The number of channels on the penultimate layer\n","            num_classes (int): Number of classes\n","            block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet\n","            norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use\n","        \"\"\"\n","        super().__init__()\n","\n","        if not inverted_residual_setting:\n","            raise ValueError(\n","                \"The inverted_residual_setting should not be empty\"\n","            )\n","        elif not (\n","            isinstance(inverted_residual_setting, Sequence)\n","            and all(\n","                [\n","                    isinstance(s, InvertedResidualConfig)\n","                    for s in inverted_residual_setting\n","                ]\n","            )\n","        ):\n","            raise TypeError(\n","                \"The inverted_residual_setting should be List[InvertedResidualConfig]\"\n","            )\n","\n","        if block is None:\n","            block = InvertedResidual\n","\n","        if norm_layer is None:\n","            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)\n","\n","        layers: List[nn.Module] = []\n","\n","        # building first layer\n","        firstconv_output_channels = inverted_residual_setting[0].input_channels\n","        layers.append(\n","            ConvNormActivation(\n","                3,\n","                firstconv_output_channels,\n","                kernel_size=3,\n","                stride=2,\n","                norm_layer=norm_layer,\n","                activation_layer=nn.Hardswish,\n","            )\n","        )\n","\n","        # building inverted residual blocks\n","        for cnf in inverted_residual_setting:\n","            layers.append(block(cnf, norm_layer))\n","\n","        # building last several layers\n","        lastconv_input_channels = inverted_residual_setting[-1].out_channels\n","        lastconv_output_channels = 6 * lastconv_input_channels\n","        layers.append(\n","            ConvNormActivation(\n","                lastconv_input_channels,\n","                lastconv_output_channels,\n","                kernel_size=1,\n","                norm_layer=norm_layer,\n","                activation_layer=nn.Hardswish,\n","            )\n","        )\n","\n","        self.features = nn.Sequential(*layers)\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(lastconv_output_channels, last_channel),\n","            nn.Hardswish(inplace=True),\n","            nn.Dropout(p=0.2, inplace=True),\n","            nn.Linear(last_channel, num_classes),\n","        )\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.ones_(m.weight)\n","                nn.init.zeros_(m.bias)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.zeros_(m.bias)\n","\n","    def _forward_impl(self, x: Tensor) -> Tensor:\n","        x = self.features(x)\n","\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","\n","        x = self.classifier(x)\n","\n","        return x\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        return self._forward_impl(x)\n","\n","\n","def _mobilenet_v3_conf(\n","    arch: str,\n","    width_mult: float = 1.0,\n","    reduced_tail: bool = False,\n","    dilated: bool = False,\n","    **kwargs: Any\n","):\n","    reduce_divider = 2 if reduced_tail else 1\n","    dilation = 2 if dilated else 1\n","\n","    bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)\n","    adjust_channels = partial(\n","        InvertedResidualConfig.adjust_channels, width_mult=width_mult\n","    )\n","\n","    if arch == \"mobilenet_v3_large\":\n","        inverted_residual_setting = [\n","            bneck_conf(16, 3, 16, 16, False, \"RE\", 1, 1),\n","            bneck_conf(16, 3, 64, 24, False, \"RE\", 2, 1),  # C1\n","            bneck_conf(24, 3, 72, 24, False, \"RE\", 1, 1),\n","            bneck_conf(24, 5, 72, 40, True, \"RE\", 2, 1),  # C2\n","            bneck_conf(40, 5, 120, 40, True, \"RE\", 1, 1),\n","            bneck_conf(40, 5, 120, 40, True, \"RE\", 1, 1),\n","            bneck_conf(40, 3, 240, 80, False, \"HS\", 2, 1),  # C3\n","            bneck_conf(80, 3, 200, 80, False, \"HS\", 1, 1),\n","            bneck_conf(80, 3, 184, 80, False, \"HS\", 1, 1),\n","            bneck_conf(80, 3, 184, 80, False, \"HS\", 1, 1),\n","            bneck_conf(80, 3, 480, 112, True, \"HS\", 1, 1),\n","            bneck_conf(112, 3, 672, 112, True, \"HS\", 1, 1),\n","            bneck_conf(\n","                112, 5, 672, 160 // reduce_divider, True, \"HS\", 2, dilation\n","            ),  # C4\n","            bneck_conf(\n","                160 // reduce_divider,\n","                5,\n","                960 // reduce_divider,\n","                160 // reduce_divider,\n","                True,\n","                \"HS\",\n","                1,\n","                dilation,\n","            ),\n","            bneck_conf(\n","                160 // reduce_divider,\n","                5,\n","                960 // reduce_divider,\n","                160 // reduce_divider,\n","                True,\n","                \"HS\",\n","                1,\n","                dilation,\n","            ),\n","        ]\n","        last_channel = adjust_channels(1280 // reduce_divider)  # C5\n","    elif arch == \"mobilenet_v3_small\":\n","        inverted_residual_setting = [\n","            bneck_conf(16, 3, 16, 16, True, \"RE\", 2, 1),  # C1\n","            bneck_conf(16, 3, 72, 24, False, \"RE\", 2, 1),  # C2\n","            bneck_conf(24, 3, 88, 24, False, \"RE\", 1, 1),\n","            bneck_conf(24, 5, 96, 40, True, \"HS\", 2, 1),  # C3\n","            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n","            bneck_conf(40, 5, 240, 40, True, \"HS\", 1, 1),\n","            bneck_conf(40, 5, 120, 48, True, \"HS\", 1, 1),\n","            bneck_conf(48, 5, 144, 48, True, \"HS\", 1, 1),\n","            bneck_conf(\n","                48, 5, 288, 96 // reduce_divider, True, \"HS\", 2, dilation\n","            ),  # C4\n","            bneck_conf(\n","                96 // reduce_divider,\n","                5,\n","                576 // reduce_divider,\n","                96 // reduce_divider,\n","                True,\n","                \"HS\",\n","                1,\n","                dilation,\n","            ),\n","            bneck_conf(\n","                96 // reduce_divider,\n","                5,\n","                576 // reduce_divider,\n","                96 // reduce_divider,\n","                True,\n","                \"HS\",\n","                1,\n","                dilation,\n","            ),\n","        ]\n","        last_channel = adjust_channels(1024 // reduce_divider)  # C5\n","    else:\n","        raise ValueError(\"Unsupported model type {}\".format(arch))\n","\n","    return inverted_residual_setting, last_channel\n","\n","\n","def _mobilenet_v3_model(\n","    arch: str,\n","    inverted_residual_setting: List[InvertedResidualConfig],\n","    last_channel: int,\n","    pretrained: bool,\n","    progress: bool,\n","    **kwargs: Any\n","):\n","    model = MobileNetV3(inverted_residual_setting, last_channel, **kwargs)\n","    if pretrained:\n","        if mobilnet_model_urls.get(arch, None) is None:\n","            raise ValueError(\"No checkpoint is available for model type {}\".format(arch))\n","        state_dict = load_state_dict_from_url(mobilnet_model_urls[arch], progress=progress)\n","        model.load_state_dict(state_dict)\n","    return model\n","\n","\n","def mobilenet_v3_large(\n","    pretrained: bool = False, progress: bool = True, **kwargs: Any\n",") -> MobileNetV3:\n","    \"\"\"\n","    Constructs a large MobileNetV3 architecture from\n","    `\"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>`_.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    arch = \"mobilenet_v3_large\"\n","    inverted_residual_setting, last_channel = _mobilenet_v3_conf(\n","        arch, **kwargs\n","    )\n","    return _mobilenet_v3_model(\n","        arch,\n","        inverted_residual_setting,\n","        last_channel,\n","        pretrained,\n","        progress,\n","        **kwargs\n","    )\n","\n","\n","def mobilenet_v3_small(\n","    pretrained: bool = True, progress: bool = True, **kwargs: Any\n",") -> MobileNetV3:\n","    \"\"\"\n","    Constructs a small MobileNetV3 architecture from\n","    `\"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>`_.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    arch = \"mobilenet_v3_small\"\n","    inverted_residual_setting, last_channel = _mobilenet_v3_conf(\n","        arch, **kwargs\n","    )\n","    return _mobilenet_v3_model(\n","        arch,\n","        inverted_residual_setting,\n","        last_channel,\n","        pretrained,\n","        progress,\n","        **kwargs\n","    )\n"],"metadata":{"id":"xIhduN5KnWHk","executionInfo":{"status":"ok","timestamp":1651268234282,"user_tz":420,"elapsed":663,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Available Backbones"],"metadata":{"id":"M8SdrmZNSw1Y"}},{"cell_type":"code","source":["BACKBONES_MAP = {\n","    \"inceptionv2\": {\n","        \"config\": [1, 1, 3],\n","        \"class\": InceptionV2,\n","    },\n","    \"resnet50\": {\n","        \"config\": None,\n","        \"class\": resnet50,\n","    },\n","    \"resnet101\": {\n","        \"config\": None,\n","        \"class\": resnet101,\n","    },\n","    \"resnet152\": {\n","        \"config\": None,\n","        \"class\": resnet152,\n","    },\n","    \"convnext_base\": {\n","        \"config\": None,\n","        \"class\": convnext_base,\n","    },\n","    \"convnext_small\": {\n","        \"config\": None,\n","        \"class\": convnext_small,\n","    },\n","    \"convnext_tiny\": {\n","        \"config\": None,\n","        \"class\": convnext_tiny, \n","    },\n","    \"mobilenetv3_small\":{\n","        \"config\": None,\n","        \"class\": mobilenet_v3_small\n","    },\n","}"],"metadata":{"id":"SEb4ZsQDS0pq","executionInfo":{"status":"ok","timestamp":1651268234283,"user_tz":420,"elapsed":9,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8iDmn9JoMTZF"},"source":["# Baseline Model"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"psQWvO4fMTZG","executionInfo":{"status":"ok","timestamp":1651268234283,"user_tz":420,"elapsed":8,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["class BaseNet(nn.Module):\n","    def __init__(self, backbone=\"resnet101\"):\n","        \"\"\"Available backbones are:\n","        - InceptionV2([1,1,3])\n","        - resnet50()\n","        - convnext_base()\n","        - resnet152()\n","        \"\"\"\n","        super().__init__()\n","        # self.backbone = InceptionV2([1, 1, 3])\n","        # self.backbone = resnet152()\n","        self.backbone_name = backbone\n","        backbone_config = BACKBONES_MAP[backbone][\"config\"]\n","        self.backbone = BACKBONES_MAP[backbone][\"class\"](backbone_config) if backbone_config is not None else BACKBONES_MAP[backbone][\"class\"]()\n","        self.fc = nn.Linear(1000, 4096) \n","        self.fc1 = nn.Linear(4096, 4096)\n","        self.fc2 = nn.Linear(4096, 4096)\n","        self.fc_calories = nn.Sequential(\n","            nn.Linear(4096, 4096),\n","            nn.Linear(4096, 1)\n","        )\n","        self.fc_mass = nn.Sequential(\n","            nn.Linear(4096, 4096),\n","            nn.Linear(4096, 1)\n","        )\n","        self.fc_mc = nn.Sequential(\n","            nn.Linear(4096, 4096),\n","            nn.Linear(4096, 3)\n","        )\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        if self.backbone_name != 'inceptionv2':\n","            x = self.fc(x) # Comment it if backbone is resnet or convnext\n","        x = self.fc2(self.fc1(x))\n","\n","        x_cal = self.fc_calories(x)\n","        x_mass = self.fc_mass(x)\n","        x_mn = self.fc_mc(x)\n","\n","        return x_cal, x_mass, x_mn"]},{"cell_type":"markdown","metadata":{"id":"5taNW4uyMTZG"},"source":["# Multi-task Loss"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"Hmt_30p0MTZG","executionInfo":{"status":"ok","timestamp":1651268234284,"user_tz":420,"elapsed":8,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["class MultiTaskLearner(nn.Module):\n","    def __init__(self, model: nn.Module, criterion=nn.L1Loss()):\n","        super(MultiTaskLearner, self).__init__()\n","        self.model = model\n","        self.criterion = criterion\n","\n","    def forward(self, x, y):\n","        # 1 x 5 Tensor [total_calories, total_mass, total_fat, total_carb, total_protein]\n","\n","        out_cal, out_mass, out_mn = self.model(x)\n","\n","        loss_calorie = self.criterion(out_cal, y[:, 0:1])\n","        \n","        loss_mass = self.criterion(out_mass, y[:, 1:2])\n","\n","        loss_mn = self.criterion(out_mn, y[:, 2:])\n","\n","        loss_total = loss_calorie + loss_mass + loss_mn\n","\n","        return loss_total"]},{"cell_type":"markdown","metadata":{"id":"NAGwpGjhfhSv"},"source":["# Delete Model"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"DZCilCtqfgos","executionInfo":{"status":"ok","timestamp":1651277319744,"user_tz":420,"elapsed":249,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["torch.cuda.empty_cache()\n","# del model"]},{"cell_type":"markdown","metadata":{"id":"SwidA51rTCTK"},"source":["# Utility Funs"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"MBVxtHj6TEE-","executionInfo":{"status":"ok","timestamp":1651268234285,"user_tz":420,"elapsed":8,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["CHECKPOINT_PATH = \"/content/drive/MyDrive/checkpoints\"\n","def create_dir_if_not_exists(dirpath: str):\n","    \"\"\"Create the specified directory with all intermediate directories if necessary.\"\"\"\n","    if not os.path.exists(dirpath):\n","        os.makedirs(dirpath)\n","\n","def save_checkpoint(\n","    epoch: int,\n","    loss: float,\n","    model: nn.Module,\n","    model_name: str,\n","    checkpoint_path: str = CHECKPOINT_PATH,\n","):\n","    create_dir_if_not_exists(checkpoint_path)\n","    torch.save(\n","        {\"epoch\": epoch, \"loss\": loss, \"model_state_dict\": model.state_dict()},\n","        os.path.join(checkpoint_path, model_name),\n","    )\n","\n","\n","def load_checkpoint(filepath: str):\n","    state_dict = torch.load(filepath)\n","    epoch, loss, model_state_dict = (\n","        state_dict[\"epoch\"],\n","        state_dict[\"loss\"],\n","        state_dict[\"model_state_dict\"],\n","    )\n","    return epoch, loss, model_state_dict"]},{"cell_type":"markdown","metadata":{"id":"XUHFw2ZWSj1U"},"source":["# Training"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["f67974ecb75641399c27a6ad9b911088","3eb697250c50444283c17d2d01f70a52","1a57e8477e1e4bf89fc57f511d73db49","75b4df4c4cbf4ab4831749416ef7a5a7","dc940e9498e144c7b7c8cafd9c5425c6","e1c7270824d94563bce7b648e5c193c6","e44867a045de45479af219bed3f5502f","cd012dbbf51c4a5da0839b30b10d584d","9e384e0e2c444180822ab94fd15fe8e3","bc58aaf8a95e4cf2a31056584e2675b0","cec350da5dc24dbab3fc27ac8e18bd8f"]},"id":"qXEIbyroMTZH","outputId":"d224b102-5bac-4edc-d1ac-3d1a0a8148a7","executionInfo":{"status":"ok","timestamp":1651268253610,"user_tz":420,"elapsed":19333,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cuda is available: True\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://s3.amazonaws.com/pytorch/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/170M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f67974ecb75641399c27a6ad9b911088"}},"metadata":{}}],"source":["print(f\"Cuda is available: {torch.cuda.is_available()}\")\n","model = BaseNet(backbone=\"resnet101\")\n","model.cuda()\n","learner = MultiTaskLearner(model)\n","\n","optimizer = torch.optim.Adam(model.parameters(), config.lr, weight_decay=0.9)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs*len(train_loader))\n","scaler = torch.cuda.amp.GradScaler()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cONTwe7yMTZH","outputId":"a8f35f04-766d-4098-fcb2-1d6dbef7a697","executionInfo":{"status":"error","timestamp":1651277282798,"user_tz":420,"elapsed":9029206,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\rTrain:   0%|          | 0/81 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n","  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/150: Train Loss 221.9507, Learning Rate 0.0002, Valid Loss 377.7618\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 2/150: Train Loss 171.3890, Learning Rate 0.0002, Valid Loss 263.3342\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 3/150: Train Loss 181.2853, Learning Rate 0.0002, Valid Loss 219.8308\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 4/150: Train Loss 159.2909, Learning Rate 0.0002, Valid Loss 205.6444\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 5/150: Train Loss 152.0633, Learning Rate 0.0002, Valid Loss 290.2989\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 6/150: Train Loss 152.1111, Learning Rate 0.0002, Valid Loss 262.8633\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 7/150: Train Loss 148.0023, Learning Rate 0.0002, Valid Loss 235.0944\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 8/150: Train Loss 153.1441, Learning Rate 0.0002, Valid Loss 263.6127\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 9/150: Train Loss 153.6985, Learning Rate 0.0002, Valid Loss 269.6106\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 10/150: Train Loss 143.3414, Learning Rate 0.0002, Valid Loss 237.4458\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 11/150: Train Loss 140.8678, Learning Rate 0.0002, Valid Loss 219.3873\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 12/150: Train Loss 140.6857, Learning Rate 0.0002, Valid Loss 226.1018\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 13/150: Train Loss 141.3959, Learning Rate 0.0002, Valid Loss 245.6431\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 14/150: Train Loss 143.2691, Learning Rate 0.0002, Valid Loss 238.8810\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 15/150: Train Loss 139.1616, Learning Rate 0.0002, Valid Loss 219.6173\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 16/150: Train Loss 134.8575, Learning Rate 0.0002, Valid Loss 223.0808\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 17/150: Train Loss 140.1564, Learning Rate 0.0002, Valid Loss 224.5688\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 18/150: Train Loss 134.3986, Learning Rate 0.0002, Valid Loss 274.0413\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 19/150: Train Loss 131.9855, Learning Rate 0.0002, Valid Loss 238.9126\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 20/150: Train Loss 128.6663, Learning Rate 0.0002, Valid Loss 228.3836\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 21/150: Train Loss 133.2028, Learning Rate 0.0002, Valid Loss 234.1721\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 22/150: Train Loss 135.9772, Learning Rate 0.0002, Valid Loss 320.1841\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 23/150: Train Loss 136.7075, Learning Rate 0.0002, Valid Loss 221.7200\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 24/150: Train Loss 139.7373, Learning Rate 0.0002, Valid Loss 213.3049\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 25/150: Train Loss 131.7008, Learning Rate 0.0002, Valid Loss 239.0313\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 26/150: Train Loss 126.6175, Learning Rate 0.0002, Valid Loss 232.1561\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 27/150: Train Loss 124.2950, Learning Rate 0.0002, Valid Loss 232.2314\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 28/150: Train Loss 124.9368, Learning Rate 0.0002, Valid Loss 224.3838\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 29/150: Train Loss 125.5551, Learning Rate 0.0002, Valid Loss 235.5479\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 30/150: Train Loss 127.9826, Learning Rate 0.0002, Valid Loss 262.1676\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 31/150: Train Loss 133.2563, Learning Rate 0.0002, Valid Loss 223.9337\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 32/150: Train Loss 125.3101, Learning Rate 0.0002, Valid Loss 224.3510\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 33/150: Train Loss 124.7634, Learning Rate 0.0002, Valid Loss 220.2817\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 34/150: Train Loss 119.9069, Learning Rate 0.0002, Valid Loss 235.6920\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 35/150: Train Loss 121.3189, Learning Rate 0.0002, Valid Loss 291.8418\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 36/150: Train Loss 124.4669, Learning Rate 0.0002, Valid Loss 237.8519\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 37/150: Train Loss 122.6428, Learning Rate 0.0002, Valid Loss 221.6067\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 38/150: Train Loss 118.6560, Learning Rate 0.0002, Valid Loss 235.7846\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 39/150: Train Loss 119.5945, Learning Rate 0.0002, Valid Loss 231.0265\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 40/150: Train Loss 119.3437, Learning Rate 0.0002, Valid Loss 231.3567\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 41/150: Train Loss 118.4664, Learning Rate 0.0002, Valid Loss 220.7179\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 42/150: Train Loss 116.7884, Learning Rate 0.0002, Valid Loss 230.3419\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 43/150: Train Loss 117.9699, Learning Rate 0.0002, Valid Loss 229.0288\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 44/150: Train Loss 115.1124, Learning Rate 0.0002, Valid Loss 227.2486\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 45/150: Train Loss 121.2406, Learning Rate 0.0002, Valid Loss 217.1616\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 46/150: Train Loss 118.3016, Learning Rate 0.0002, Valid Loss 217.9488\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 47/150: Train Loss 115.4689, Learning Rate 0.0002, Valid Loss 231.3751\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 48/150: Train Loss 115.9520, Learning Rate 0.0002, Valid Loss 222.7532\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 49/150: Train Loss 117.0138, Learning Rate 0.0002, Valid Loss 234.8081\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 50/150: Train Loss 113.6670, Learning Rate 0.0002, Valid Loss 229.9703\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 51/150: Train Loss 114.2997, Learning Rate 0.0001, Valid Loss 231.0137\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 52/150: Train Loss 112.0457, Learning Rate 0.0001, Valid Loss 226.5978\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 53/150: Train Loss 115.4547, Learning Rate 0.0001, Valid Loss 220.3488\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 54/150: Train Loss 112.0613, Learning Rate 0.0001, Valid Loss 223.2859\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 55/150: Train Loss 114.0909, Learning Rate 0.0001, Valid Loss 230.8421\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 56/150: Train Loss 112.3962, Learning Rate 0.0001, Valid Loss 229.1677\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 57/150: Train Loss 111.6785, Learning Rate 0.0001, Valid Loss 233.4399\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 58/150: Train Loss 111.7352, Learning Rate 0.0001, Valid Loss 230.4537\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 59/150: Train Loss 115.6739, Learning Rate 0.0001, Valid Loss 226.6488\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 60/150: Train Loss 108.9366, Learning Rate 0.0001, Valid Loss 221.6654\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 61/150: Train Loss 110.9883, Learning Rate 0.0001, Valid Loss 223.4752\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 62/150: Train Loss 109.5424, Learning Rate 0.0001, Valid Loss 236.1560\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 63/150: Train Loss 108.9422, Learning Rate 0.0001, Valid Loss 230.4475\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 64/150: Train Loss 110.4916, Learning Rate 0.0001, Valid Loss 224.0586\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 65/150: Train Loss 108.4572, Learning Rate 0.0001, Valid Loss 221.4724\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 66/150: Train Loss 107.1817, Learning Rate 0.0001, Valid Loss 238.2341\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 67/150: Train Loss 106.6565, Learning Rate 0.0001, Valid Loss 223.2905\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 68/150: Train Loss 106.1881, Learning Rate 0.0001, Valid Loss 224.9994\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 69/150: Train Loss 105.8443, Learning Rate 0.0001, Valid Loss 223.6492\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 70/150: Train Loss 106.2793, Learning Rate 0.0001, Valid Loss 220.8647\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 71/150: Train Loss 105.0684, Learning Rate 0.0001, Valid Loss 215.1338\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 72/150: Train Loss 106.4769, Learning Rate 0.0001, Valid Loss 225.0379\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 73/150: Train Loss 105.3642, Learning Rate 0.0001, Valid Loss 231.3692\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 74/150: Train Loss 106.3323, Learning Rate 0.0001, Valid Loss 225.1525\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 75/150: Train Loss 107.3248, Learning Rate 0.0001, Valid Loss 230.4318\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 76/150: Train Loss 103.8907, Learning Rate 0.0001, Valid Loss 224.1721\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 77/150: Train Loss 103.3434, Learning Rate 0.0001, Valid Loss 239.7738\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 78/150: Train Loss 103.3665, Learning Rate 0.0001, Valid Loss 224.5966\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 79/150: Train Loss 103.5556, Learning Rate 0.0001, Valid Loss 227.9807\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 80/150: Train Loss 102.6148, Learning Rate 0.0001, Valid Loss 226.5151\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 81/150: Train Loss 103.0638, Learning Rate 0.0001, Valid Loss 227.9959\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 82/150: Train Loss 102.6347, Learning Rate 0.0001, Valid Loss 225.7281\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 83/150: Train Loss 101.1530, Learning Rate 0.0001, Valid Loss 223.4055\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 84/150: Train Loss 102.3259, Learning Rate 0.0001, Valid Loss 223.4158\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 85/150: Train Loss 100.9831, Learning Rate 0.0001, Valid Loss 232.7119\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 86/150: Train Loss 101.0678, Learning Rate 0.0001, Valid Loss 224.0012\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 87/150: Train Loss 100.7666, Learning Rate 0.0001, Valid Loss 224.5551\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 88/150: Train Loss 101.9120, Learning Rate 0.0001, Valid Loss 230.1535\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 89/150: Train Loss 99.1335, Learning Rate 0.0001, Valid Loss 225.8305\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 90/150: Train Loss 99.4145, Learning Rate 0.0001, Valid Loss 223.6492\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 91/150: Train Loss 99.4559, Learning Rate 0.0001, Valid Loss 224.2702\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 92/150: Train Loss 100.0297, Learning Rate 0.0001, Valid Loss 226.5089\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 93/150: Train Loss 99.1058, Learning Rate 0.0001, Valid Loss 226.6150\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 94/150: Train Loss 98.5129, Learning Rate 0.0001, Valid Loss 226.9831\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 95/150: Train Loss 98.8553, Learning Rate 0.0001, Valid Loss 230.8495\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 96/150: Train Loss 97.8052, Learning Rate 0.0001, Valid Loss 227.6001\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 97/150: Train Loss 97.4401, Learning Rate 0.0001, Valid Loss 226.6004\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 98/150: Train Loss 99.2944, Learning Rate 0.0001, Valid Loss 225.8464\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 99/150: Train Loss 97.3106, Learning Rate 0.0001, Valid Loss 226.1276\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 100/150: Train Loss 96.7975, Learning Rate 0.0001, Valid Loss 234.4702\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 101/150: Train Loss 97.0310, Learning Rate 0.0000, Valid Loss 233.8487\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 102/150: Train Loss 96.7113, Learning Rate 0.0000, Valid Loss 230.8539\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 103/150: Train Loss 97.2864, Learning Rate 0.0000, Valid Loss 231.0946\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 104/150: Train Loss 96.0981, Learning Rate 0.0000, Valid Loss 230.7626\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 105/150: Train Loss 97.2773, Learning Rate 0.0000, Valid Loss 235.8502\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 106/150: Train Loss 96.2506, Learning Rate 0.0000, Valid Loss 230.1167\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 107/150: Train Loss 95.3325, Learning Rate 0.0000, Valid Loss 230.6268\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 108/150: Train Loss 95.4126, Learning Rate 0.0000, Valid Loss 229.8191\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 109/150: Train Loss 95.8544, Learning Rate 0.0000, Valid Loss 228.0986\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 110/150: Train Loss 95.2426, Learning Rate 0.0000, Valid Loss 227.7809\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 111/150: Train Loss 94.8903, Learning Rate 0.0000, Valid Loss 229.6695\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 112/150: Train Loss 95.4880, Learning Rate 0.0000, Valid Loss 230.4352\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 113/150: Train Loss 94.6279, Learning Rate 0.0000, Valid Loss 230.2465\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 114/150: Train Loss 94.3091, Learning Rate 0.0000, Valid Loss 228.7391\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 115/150: Train Loss 93.9853, Learning Rate 0.0000, Valid Loss 229.0617\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 116/150: Train Loss 94.2679, Learning Rate 0.0000, Valid Loss 229.3495\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 117/150: Train Loss 94.4220, Learning Rate 0.0000, Valid Loss 230.2129\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 118/150: Train Loss 93.3248, Learning Rate 0.0000, Valid Loss 232.9382\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 119/150: Train Loss 94.2552, Learning Rate 0.0000, Valid Loss 229.8367\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 120/150: Train Loss 93.4414, Learning Rate 0.0000, Valid Loss 232.5071\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Epoch 121/150: Train Loss 93.6756, Learning Rate 0.0000, Valid Loss 230.9434\n"]},{"output_type":"stream","name":"stderr","text":["Train:   7%|▋         | 6/81 [00:04<00:57,  1.30it/s, loss=88.0148, lr=0.0000]"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-6117ecdb192a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Update # correct & loss as we go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Compute training metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(config.epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n","\n","    for i, (x, y) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        x = x.cuda()\n","        y = y.cuda()\n","\n","        # with torch.cuda.amp.autocast():     \n","        loss = learner(x, y)\n","\n","        # Update # correct & loss as we go\n","        total_loss += float(loss)\n","\n","        # Compute training metrics\n","        train_loss = float(total_loss / (i + 1))\n","        cur_lr = float(optimizer.param_groups[0]['lr'])\n","\n","\n","        # tqdm lets you add some details so you can monitor training as you train.\n","        batch_bar.set_postfix(\n","            loss=\"{:.04f}\".format(train_loss),\n","            lr=\"{:.04f}\".format(cur_lr))\n","        \n","        # Another couple things you need for FP16. \n","        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n","        # loss.backward()\n","        scaler.step(optimizer) # This is a replacement for optimizer.step()\n","        # optimizer.step()\n","        scaler.update() # This is something added just for FP16\n","\n","        scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n","\n","        batch_bar.update() # Update tqdm bar\n","\n","    batch_bar.close() # You need this to close the tqdm bar\n","\n","    train_loss = total_loss / len(train_loader)\n","    \n","    # Save the model every 3 epochs\n","    if epoch % 3 == 0:\n","        save_checkpoint(epoch, train_loss, model, \"resnet101\")\n","\n","    # You can add validation per-epoch here if you would like\n","    model.eval()\n","    batch_bar = tqdm(total=len(valid_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n","    total_loss = 0\n","    for i, (x, y) in enumerate(valid_loader):\n","\n","        x = x.cuda()\n","        y = y.cuda()\n","\n","        with torch.no_grad():\n","            loss = learner(x, y)\n","        \n","\n","        total_loss += float(loss)\n","\n","        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))))\n","\n","        batch_bar.update()\n","        \n","    batch_bar.close()\n","\n","    # scheduler.step(float(total_loss / (i + 1)))\n","\n","    valid_loss = total_loss / len(valid_loader)\n","\n","    print(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}, Valid Loss {:.04f}\".format(\n","        epoch + 1, config.epochs, train_loss, cur_lr, valid_loss))\n"]},{"cell_type":"markdown","metadata":{"id":"n2V87c8BGPQw"},"source":["# Evaluate Stats"]},{"cell_type":"markdown","metadata":{"id":"Ozf98y6QHqzM"},"source":["## Copy Ground Truths to Colab "]},{"cell_type":"code","execution_count":22,"metadata":{"id":"g1swvG5QHvN_","executionInfo":{"status":"ok","timestamp":1651277297226,"user_tz":420,"elapsed":7906,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["!cp /content/drive/MyDrive/11785/project/ground_truth.csv /content/data/metadata/"]},{"cell_type":"markdown","metadata":{"id":"naHMWg8WSg36"},"source":["## Dataset for Evaluation"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"JE0uN76aSi2e","executionInfo":{"status":"ok","timestamp":1651277299857,"user_tz":420,"elapsed":294,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["class EvalDataset(Dataset):\n","\n","    def __init__(self, data_dir, transforms=Compose([CenterCrop((256, 256)), ToTensor()]), labels=labels_dict):\n","        self.data_dir = data_dir\n","        self.transforms = transforms\n","        self.labels = labels\n","\n","        # # ['dish_1556572657', 'dish_1556573514', 'dish_1556575014', 'dish_1556575083', 'dish_1556575124', 'dish_1556575273', 'dish_1556575327']\n","        dirs = os.listdir(self.data_dir)\n","\n","        self.dish_ids = []\n","        for dir in dirs:\n","            if \"rgb.png\" in os.listdir(os.path.join(self.data_dir,dir)):\n","                self.dish_ids.append(dir)\n","\n","        self.dish_ids.sort()\n","\n","        self.img_paths = list(\n","            map(\n","                lambda fname: os.path.join(self.data_dir, fname),\n","                self.dish_ids,\n","            )\n","        )\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        rgb_path = f\"{self.img_paths[idx]}/rgb.png\"\n","        dish_id = self.dish_ids[idx]\n","        transformed_img = self.transforms(Image.open(rgb_path))\n","        # Return the dish id for writing the csv file\n","        return transformed_img, dish_id"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"C5vjIWaHSpxB","executionInfo":{"status":"ok","timestamp":1651277300344,"user_tz":420,"elapsed":6,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["torch.cuda.empty_cache()\n","eval_train_data = EvalDataset(TRAIN_DIR, labels=labels_dict)\n","eval_val_data = EvalDataset(VALID_DIR, labels=labels_dict)\n","\n","eval_train_loader = DataLoader(eval_train_data, batch_size=16, shuffle=False, num_workers=2)\n","eval_val_loader = DataLoader(eval_val_data, batch_size=16, shuffle=False, num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"6jRd5-8LQ6_m"},"source":["## (Optional) Load Checkpoint"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"FkbF8Lf5Q9lX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651277337112,"user_tz":420,"elapsed":7665,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}},"outputId":"6d587801-9fff-4177-f683-94568aa0b7f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BaseNet(\n","  (backbone): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n","    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n","  )\n","  (fc): Linear(in_features=1000, out_features=4096, bias=True)\n","  (fc1): Linear(in_features=4096, out_features=4096, bias=True)\n","  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n","  (fc_calories): Sequential(\n","    (0): Linear(in_features=4096, out_features=4096, bias=True)\n","    (1): Linear(in_features=4096, out_features=1, bias=True)\n","  )\n","  (fc_mass): Sequential(\n","    (0): Linear(in_features=4096, out_features=4096, bias=True)\n","    (1): Linear(in_features=4096, out_features=1, bias=True)\n","  )\n","  (fc_mc): Sequential(\n","    (0): Linear(in_features=4096, out_features=4096, bias=True)\n","    (1): Linear(in_features=4096, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":27}],"source":["model = BaseNet()\n","_, _, model_state_dict = load_checkpoint(f\"{CHECKPOINT_PATH}/resnet101\")\n","model.load_state_dict(model_state_dict)\n","model.cuda()"]},{"cell_type":"markdown","metadata":{"id":"2IL0MKozPfkr"},"source":["## Inference on training and testing data"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWMQXbXpPitc","outputId":"0c7da574-81fc-44c3-f847-b7c27ed6859c","executionInfo":{"status":"ok","timestamp":1651277375875,"user_tz":420,"elapsed":34105,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n","  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"]}],"source":["prediction_filepath = \"/content/data/metadata/outputs.csv\"\n","# if os.path.exists(prediction_filepath):\n","#     os.remove(prediction_filepath)\n","\n","model.eval()\n","batch_bar = tqdm(total=len(eval_train_loader), dynamic_ncols=True, position=0, leave=False, desc='Eval_Train')\n","results_all = None\n","# Inference on training data\n","for i, (x, y) in enumerate(eval_train_loader):\n","\n","    x = x.cuda()\n","    dish_ids = np.array(list(y))\n","    dish_ids = dish_ids.reshape(dish_ids.shape[0],1)\n","\n","    cal, mass, mn = model(x)\n","\n","    results = torch.cat((cal,mass,mn), 1).detach().cpu().numpy()\n","\n","    results = np.concatenate((dish_ids, results), 1)\n","    \n","    if results_all is None:\n","        results_all = results\n","    else:\n","        results_all = np.concatenate((results_all, results), 0)\n","\n","    del cal, mass, mn\n","    torch.cuda.empty_cache()\n","\n","    batch_bar.update()\n","    \n","batch_bar.close()\n","torch.cuda.empty_cache()\n","# Inference on validation data\n","batch_bar = tqdm(total=len(eval_val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n","for i, (x, y) in enumerate(eval_val_loader):\n","\n","    x = x.cuda()\n","    dish_ids = np.array(list(y))\n","    dish_ids = dish_ids.reshape(dish_ids.shape[0],1)\n","\n","    cal, mass, mn = model(x)\n","\n","    results = torch.cat((cal,mass,mn), 1).detach().cpu().numpy()\n","\n","    results = np.concatenate((dish_ids, results), 1)\n","    \n","    if results_all is None:\n","        results_all = results\n","    else:\n","        results_all = np.concatenate((results_all, results), 0)\n","\n","    del cal, mass, mn\n","    torch.cuda.empty_cache()\n","\n","    batch_bar.update()\n","    \n","batch_bar.close()"]},{"cell_type":"code","source":["# Write to csv\n","np.savetxt(prediction_filepath, results_all, delimiter=\",\", fmt='%s,%s,%s,%s,%s,%s')"],"metadata":{"id":"eamekPDibr7s","executionInfo":{"status":"ok","timestamp":1651277376263,"user_tz":420,"elapsed":403,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"kmqPuW8SGQzY","executionInfo":{"status":"ok","timestamp":1651277377974,"user_tz":420,"elapsed":1713,"user":{"displayName":"Ricardo Wang","userId":"08964684308248908958"}}},"outputs":[],"source":["r\"\"\"Script to compute statistics on nutrition predictions.\n","\n","This script takes in a csv of nutrition predictions and computes absolute and\n","percentage mean average error values comparable to the metrics used to eval\n","models in the Nutrition5k paper. The input csv file of nutrition predictions\n","should be in the form of:\n","dish_id, calories, mass, carbs, protein\n","And the groundtruth values will be pulled from the metadata csv file provided\n","in the Nutrition5k dataset release where the first 5 fields are also:\n","dish_id, calories, mass, carbs, protein\n","\n","Example Usage:\n","python compute_statistics.py path/to/groundtruth.csv path/to/predictions.csv \\\n","path/to/output_statistics.json\n","\"\"\"\n","\n","import json\n","from os import path\n","import statistics\n","import sys\n","\n","DISH_ID_INDEX = 0\n","DATA_FIELDNAMES = [\"dish_id\", \"calories\", \"mass\", \"fat\", \"carb\", \"protein\"]\n","\n","\n","def ReadCsvData(filepath):\n","  if not path.exists(filepath):\n","    raise Exception(\"File %s not found\" % path)\n","  parsed_data = {}\n","  with open(filepath, \"r\") as f_in:\n","    filelines = f_in.readlines()\n","    for line in filelines:\n","      data_values = line.strip().split(\",\")\n","      parsed_data[data_values[DISH_ID_INDEX]] = data_values\n","  return parsed_data\n","\n","# groundtruth_csv_path = \"/content/data/metadata/ground_truth.csv\"\n","groundtruth_csv_path = \"/content/drive/MyDrive/11785/project/ground_truth.csv\"\n","predictions_csv_path = prediction_filepath\n","output_path = \"/content/data/metadata/eval_results.json\"\n","\n","groundtruth_data = ReadCsvData(groundtruth_csv_path)\n","prediction_data = ReadCsvData(predictions_csv_path)\n","\n","groundtruth_values = {}\n","err_values = {}\n","output_stats = {}\n","\n","for field in DATA_FIELDNAMES[1:]:\n","  groundtruth_values[field] = []\n","  err_values[field] = []\n","\n","for dish_id in prediction_data:\n","  for i in range(1, len(DATA_FIELDNAMES)):\n","    groundtruth_values[DATA_FIELDNAMES[i]].append(\n","        float(groundtruth_data[dish_id][i]))\n","    err_values[DATA_FIELDNAMES[i]].append(abs(\n","        float(prediction_data[dish_id][i])\n","        - float(groundtruth_data[dish_id][i])))\n","\n","for field in DATA_FIELDNAMES[1:]:\n","  output_stats[field + \"_MAE\"] = statistics.mean(err_values[field])\n","  output_stats[field + \"_MAE_%\"] = (100 * statistics.mean(err_values[field]) /\n","                                    statistics.mean(groundtruth_values[field]))\n","\n","with open(output_path, \"w\") as f_out:\n","  f_out.write(json.dumps(output_stats))\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["D-QNNGMCMTY3","5NXFw1rhMTY7","msbOJn4yNcIq","H4N---LU7A6W","BnF7W4O37EPg","28paTv3yY-E6","n59ANLHGMTY9","EKfNoKuIMTY9","L461g1bEMTY_","TD2SzXIYMTY_","HxLtWU6WMTZA","65hoT-vkMTZB","5pAxIycIMTZD","U8khcs7eeugO","BR4hSKp6RiFz","magQzDMjnTgB","5taNW4uyMTZG","SwidA51rTCTK","naHMWg8WSg36","6jRd5-8LQ6_m"],"machine_shape":"hm","name":"nutrition5k_eval.ipynb","provenance":[]},"interpreter":{"hash":"af28af081fbc6591a0657d60a0d8fa83ec1369d1ecf4b5402213d8282a449a4e"},"kernelspec":{"display_name":"Python 3.9.10 ('intro2dl')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f67974ecb75641399c27a6ad9b911088":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3eb697250c50444283c17d2d01f70a52","IPY_MODEL_1a57e8477e1e4bf89fc57f511d73db49","IPY_MODEL_75b4df4c4cbf4ab4831749416ef7a5a7"],"layout":"IPY_MODEL_dc940e9498e144c7b7c8cafd9c5425c6"}},"3eb697250c50444283c17d2d01f70a52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1c7270824d94563bce7b648e5c193c6","placeholder":"​","style":"IPY_MODEL_e44867a045de45479af219bed3f5502f","value":"100%"}},"1a57e8477e1e4bf89fc57f511d73db49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd012dbbf51c4a5da0839b30b10d584d","max":178728960,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e384e0e2c444180822ab94fd15fe8e3","value":178728960}},"75b4df4c4cbf4ab4831749416ef7a5a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc58aaf8a95e4cf2a31056584e2675b0","placeholder":"​","style":"IPY_MODEL_cec350da5dc24dbab3fc27ac8e18bd8f","value":" 170M/170M [00:06&lt;00:00, 35.6MB/s]"}},"dc940e9498e144c7b7c8cafd9c5425c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1c7270824d94563bce7b648e5c193c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e44867a045de45479af219bed3f5502f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd012dbbf51c4a5da0839b30b10d584d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e384e0e2c444180822ab94fd15fe8e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc58aaf8a95e4cf2a31056584e2675b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec350da5dc24dbab3fc27ac8e18bd8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}