{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Expectation\n",
    "\n",
    "- Baseline\n",
    "- Experiment (i.e., something different; e.x., spreadsheet)\n",
    "- Timeline (what we have done, and what we will be doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    ToTensor,\n",
    ")\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./../sample_data\"\n",
    "METADATA_DIR = f\"{DATA_PATH}/metadata\"\n",
    "IMAGERY_DIR = f\"{DATA_PATH}/imagery/realsense_overhead\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_variable_cols(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"https://stackoverflow.com/a/57824142.\n",
    "    We only read the first 6 columns to retrieve required labels.\n",
    "    \"\"\"\n",
    "    ### Loop the data lines\n",
    "    with open(filepath, 'r') as temp_f:\n",
    "        # get No of columns in each line\n",
    "        col_count = [ len(l.split(\",\")) for l in temp_f.readlines() ]\n",
    "\n",
    "    ### Generate column names  (names will be 0, 1, 2, ..., maximum columns - 1)\n",
    "    column_names = [i for i in range(0, max(col_count))]\n",
    "\n",
    "    ### Read csv\n",
    "    return pd.read_csv(filepath, header=None, delimiter=\",\", names=column_names, low_memory=False).iloc[:,:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingredient and Dish Metadata (Groun Truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Format\n",
    "\n",
    "### Training-testing data\n",
    "\n",
    "- \"imagery/realsense_overhead/dish_<id>\" contains the images as the input data\n",
    "- \"dish_ids\" contains training-testing splits\n",
    "\n",
    "### Labels (metadata)\n",
    "\n",
    "All labels need to be preprocessed. For each dish, we need to extract the following:\n",
    "- total calorie\n",
    "- mass (optional according to the paper)\n",
    "- the amount of the three macronutrients (fat, carb, protein)\n",
    "\n",
    "It doesn't seem that bad - we don't need to process the ingredients because they are purely there for constructing the labels. For our multi-task learning, we only need to have the above labels. The three tasks are:\n",
    "\n",
    "1. Calorie\n",
    "2. Macronutrients (fat, carb, protein)\n",
    "3. Mass (optional)\n",
    "\n",
    "这样一来我们可以把labels和image data放在一起，每次返回input和expected output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dish Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata for dishes has variable numbers of columns per row.\n",
    "# Can do similar stuff to dish_metadata_cafe2.csv\n",
    "# The first 6 columns: [dish_id, total_calories, total_mass, total_fat, total_carb, total_protein]\n",
    "dish_metadata_1 = read_csv_variable_cols(f\"{METADATA_DIR}/dish_metadata_cafe1.csv\")\n",
    "# Rename the columns\n",
    "dish_metadata_1 = dish_metadata_1.rename(columns={0:\"dish_id\", 1:\"total_calories\", 2:\"total_mass\", 3:\"total_fat\", 4:\"total_carb\", 5:\"total_protein\"})\n",
    "\n",
    "dish_metadata_2 = read_csv_variable_cols(f\"{METADATA_DIR}/dish_metadata_cafe2.csv\")\n",
    "# Rename the columns\n",
    "dish_metadata_2 = dish_metadata_2.rename(columns={0:\"dish_id\", 1:\"total_calories\", 2:\"total_mass\", 3:\"total_fat\", 4:\"total_carb\", 5:\"total_protein\"})\n",
    "\n",
    "dish_metadata = pd.concat((dish_metadata_1, dish_metadata_2), ignore_index=True)\n",
    "# Convert to dictionary\n",
    "labels_dict = dish_metadata.set_index(\"dish_id\").to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epochs': 10,\n",
    "    'batch_size': 128,\n",
    "    'lr': 0.1,\n",
    "}\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, config):\n",
    "        for k, v in config.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "config = Config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBDataset(Dataset):\n",
    "    \"\"\"4.2 The input resolution to the\n",
    "    network is a 256x256 image, where images were downsized\n",
    "    and center cropped in order to retain the most salient dish\n",
    "    region.\n",
    "\n",
    "    我们baseline应该只用RGB就行 (根据4.2).\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Also return the metadata here?\n",
    "    def __init__(self, data_dir, transforms=Compose([CenterCrop((256, 256)), ToTensor()]), labels=labels_dict, train=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.transforms = transforms\n",
    "        self.labels = labels\n",
    "        self.train = train\n",
    "\n",
    "        # # ['dish_1556572657', 'dish_1556573514', 'dish_1556575014', 'dish_1556575083', 'dish_1556575124', 'dish_1556575273', 'dish_1556575327']\n",
    "        self.dish_ids = sorted(os.listdir(self.data_dir))\n",
    "\n",
    "        self.img_paths = list(\n",
    "            map(\n",
    "                lambda fname: os.path.join(self.data_dir, fname),\n",
    "                self.dish_ids,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rgb_path = f\"{self.img_paths[idx]}/rgb.png\"\n",
    "        dish_id = self.dish_ids[idx]\n",
    "        transformed_img = self.transforms(Image.open(rgb_path))\n",
    "        if self.train:\n",
    "            label = torch.tensor(list(self.labels[dish_id].values()))\n",
    "            return transformed_img, label\n",
    "        else:\n",
    "            return transformed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = IMAGERY_DIR\n",
    "VALID_DIR = IMAGERY_DIR\n",
    "TEST_DIR = IMAGERY_DIR\n",
    "\n",
    "train_dataset = RGBDataset(TRAIN_DIR, labels=labels_dict)\n",
    "valid_dataset = RGBDataset(VALID_DIR, labels=labels_dict)\n",
    "test_dataset = RGBDataset(TEST_DIR, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "num_training_batches = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBNReLU(in_channels,out_channels,kernel_size,stride=1,padding=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,padding=padding),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU6(inplace=True),\n",
    "    )\n",
    "\n",
    "def ConvBNReLUFactorization(in_channels,out_channels,kernel_sizes,paddings):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_sizes, stride=1,padding=paddings),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "class InceptionV2ModuleA(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels1,out_channels2reduce, out_channels2, out_channels3reduce, out_channels3, out_channels4):\n",
    "        super(InceptionV2ModuleA, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1),\n",
    "            ConvBNReLU(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=in_channels,out_channels=out_channels3reduce,kernel_size=1),\n",
    "            ConvBNReLU(in_channels=out_channels3reduce, out_channels=out_channels3, kernel_size=3, padding=1),\n",
    "            ConvBNReLU(in_channels=out_channels3, out_channels=out_channels3, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out4 = self.branch4(x)\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return out\n",
    "\n",
    "class InceptionV2ModuleB(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels1,out_channels2reduce, out_channels2, out_channels3reduce, out_channels3, out_channels4):\n",
    "        super(InceptionV2ModuleB, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1),\n",
    "            ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2reduce, kernel_sizes=[1,3],paddings=[0,1]),\n",
    "            ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_sizes=[3,1],paddings=[1, 0]),\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=in_channels,out_channels=out_channels3reduce,kernel_size=1),\n",
    "            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3reduce,kernel_sizes=[1, 3], paddings=[0, 1]),\n",
    "            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3reduce,kernel_sizes=[3, 1], paddings=[1, 0]),\n",
    "            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3reduce, kernel_sizes=[1, 3], paddings=[0, 1]),\n",
    "            ConvBNReLUFactorization(in_channels=out_channels3reduce, out_channels=out_channels3,kernel_sizes=[3, 1], paddings=[1, 0]),\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out4 = self.branch4(x)\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return out\n",
    "\n",
    "class InceptionV2ModuleC(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels1,out_channels2reduce, out_channels2, out_channels3reduce, out_channels3, out_channels4):\n",
    "        super(InceptionV2ModuleC, self).__init__()\n",
    "\n",
    "        self.branch1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels1,kernel_size=1)\n",
    "\n",
    "        self.branch2_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1)\n",
    "        self.branch2_conv2a = ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_sizes=[1,3],paddings=[0,1])\n",
    "        self.branch2_conv2b = ConvBNReLUFactorization(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_sizes=[3,1],paddings=[1,0])\n",
    "\n",
    "        self.branch3_conv1 = ConvBNReLU(in_channels=in_channels,out_channels=out_channels3reduce,kernel_size=1)\n",
    "        self.branch3_conv2 = ConvBNReLU(in_channels=out_channels3reduce, out_channels=out_channels3, kernel_size=3,stride=1,padding=1)\n",
    "        self.branch3_conv3a = ConvBNReLUFactorization(in_channels=out_channels3, out_channels=out_channels3, kernel_sizes=[3, 1],paddings=[1, 0])\n",
    "        self.branch3_conv3b = ConvBNReLUFactorization(in_channels=out_channels3, out_channels=out_channels3, kernel_sizes=[1, 3],paddings=[0, 1])\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.branch1(x)\n",
    "        x2 = self.branch2_conv1(x)\n",
    "        out2 = torch.cat([self.branch2_conv2a(x2), self.branch2_conv2b(x2)],dim=1)\n",
    "        x3 = self.branch3_conv2(self.branch3_conv1(x))\n",
    "        out3 = torch.cat([self.branch3_conv3a(x3), self.branch3_conv3b(x3)], dim=1)\n",
    "        out4 = self.branch4(x)\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return out\n",
    "\n",
    "class InceptionV3ModuleD(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels1reduce,out_channels1,out_channels2reduce, out_channels2):\n",
    "        super(InceptionV3ModuleD, self).__init__()\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels1reduce, kernel_size=1),\n",
    "            ConvBNReLU(in_channels=out_channels1reduce, out_channels=out_channels1, kernel_size=3,stride=2,padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=in_channels, out_channels=out_channels2reduce, kernel_size=1),\n",
    "            ConvBNReLU(in_channels=out_channels2reduce, out_channels=out_channels2, kernel_size=3, stride=1, padding=1),\n",
    "            ConvBNReLU(in_channels=out_channels2, out_channels=out_channels2, kernel_size=3, stride=2,padding=1),\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out = torch.cat([out1, out2, out3], dim=1)\n",
    "        return out\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels):\n",
    "        super(InceptionAux, self).__init__()\n",
    "\n",
    "        self.auxiliary_avgpool = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        self.auxiliary_conv1 = ConvBNReLU(in_channels=in_channels, out_channels=128, kernel_size=1)\n",
    "        self.auxiliary_conv2 = nn.Conv2d(in_channels=128, out_channels=768, kernel_size=5,stride=1)\n",
    "        self.auxiliary_dropout = nn.Dropout(p=0.7)\n",
    "        self.auxiliary_linear1 = nn.Linear(in_features=768, out_features=out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.auxiliary_conv1(self.auxiliary_avgpool(x))\n",
    "        x = self.auxiliary_conv2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.auxiliary_linear1(self.auxiliary_dropout(x))\n",
    "        return out\n",
    "\n",
    "class InceptionV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, stage='train'):\n",
    "        super(InceptionV2, self).__init__()\n",
    "        self.stage = stage\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=3, out_channels=64, kernel_size=7,stride=2,padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2,padding=1),\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            ConvBNReLU(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2,padding=1),\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            InceptionV2ModuleA(in_channels=192,out_channels1=64,out_channels2reduce=64, out_channels2=64, out_channels3reduce=64, out_channels3=96, out_channels4=32),\n",
    "            InceptionV2ModuleA(in_channels=256, out_channels1=64, out_channels2reduce=64, out_channels2=96,out_channels3reduce=64, out_channels3=96, out_channels4=64),\n",
    "            InceptionV3ModuleD(in_channels=320, out_channels1reduce=128, out_channels1=160, out_channels2reduce=64,out_channels2=96),\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            InceptionV2ModuleB(in_channels=576, out_channels1=224, out_channels2reduce=64, out_channels2=96,out_channels3reduce=96, out_channels3=128, out_channels4=128),\n",
    "            InceptionV2ModuleB(in_channels=576, out_channels1=192, out_channels2reduce=96, out_channels2=128,out_channels3reduce=96, out_channels3=128, out_channels4=128),\n",
    "            InceptionV2ModuleB(in_channels=576, out_channels1=160, out_channels2reduce=128, out_channels2=160,out_channels3reduce=128, out_channels3=128, out_channels4=128),\n",
    "            InceptionV2ModuleB(in_channels=576, out_channels1=96, out_channels2reduce=128, out_channels2=192,out_channels3reduce=160, out_channels3=160, out_channels4=128),\n",
    "            InceptionV3ModuleD(in_channels=576, out_channels1reduce=128, out_channels1=192, out_channels2reduce=192,out_channels2=256),\n",
    "        )\n",
    "\n",
    "        self.block5 = nn.Sequential(\n",
    "            InceptionV2ModuleC(in_channels=1024, out_channels1=352, out_channels2reduce=192, out_channels2=160,out_channels3reduce=160, out_channels3=112, out_channels4=128),\n",
    "            InceptionV2ModuleC(in_channels=1024, out_channels1=352, out_channels2reduce=192, out_channels2=160,\n",
    "                               out_channels3reduce=192, out_channels3=112, out_channels4=128)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = InceptionV2([1, 1, 3])\n",
    "        self.fc1 = nn.Linear(4096, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc_calories = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.Linear(4096, 1)\n",
    "        )\n",
    "        self.fc_mass = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.Linear(4096, 1)\n",
    "        )\n",
    "        self.fc_mc = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.Linear(4096, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.fc2(self.fc1(x))\n",
    "\n",
    "        x_cal = self.fc_calories(x)\n",
    "        x_mass = self.fc_mass(x)\n",
    "        x_mn = self.fc_mc(x)\n",
    "\n",
    "        return x_cal, x_mass, x_mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-task Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskLearner(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super(MultiTaskLearner, self).__init__()\n",
    "        self.model = model\n",
    "        self.criterion = nn.L1Loss()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # 1 x 5 Tensor [total_calories, total_mass, total_fat, total_carb, total_protein]\n",
    "        # [0] - total_calories \n",
    "\n",
    "        out_cal, out_mass, out_mn = self.model(x)\n",
    "\n",
    "        loss_calorie = self.criterion(out_cal, y[:, 0])\n",
    "        \n",
    "        loss_mass = self.criterion(out_mass, y[:, 1])\n",
    "\n",
    "        loss_mn = self.criterion(out_mn, y[:, 2:])\n",
    "\n",
    "        loss_total = loss_calorie + loss_mass + loss_mn\n",
    "\n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseNet()\n",
    "model.cuda()\n",
    "learner = MultiTaskLearner(model)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-4)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        with torch.cuda.amp.autocast():     \n",
    "            loss = learner(x, y)\n",
    "\n",
    "        # Update # correct & loss as we go\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        # Compute training metrics\n",
    "        train_loss = float(total_loss / (i + 1))\n",
    "        cur_lr = float(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "\n",
    "        # tqdm lets you add some details so you can monitor training as you train.\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(train_loss),\n",
    "            lr=\"{:.04f}\".format(cur_lr))\n",
    "        \n",
    "        # Another couple things you need for FP16. \n",
    "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
    "        scaler.update() # This is something added just for FP16\n",
    "\n",
    "        # scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "\n",
    "    batch_bar.close() # You need this to close the tqdm bar\n",
    "\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # You can add validation per-epoch here if you would like\n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(valid_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "    total_loss = 0\n",
    "    for i, (x, y) in enumerate(valid_loader):\n",
    "\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = learner(x, y)\n",
    "\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}%\".format(float(total_loss / (i + 1))))\n",
    "\n",
    "        batch_bar.update()\n",
    "        \n",
    "    batch_bar.close()\n",
    "\n",
    "    # scheduler.step(float(total_loss / (i + 1)))\n",
    "\n",
    "    valid_loss = total_loss / len(valid_loader)\n",
    "\n",
    "    print(\"Epoch {}/{}: Train Loss {:.04f}, Learning Rate {:.04f}, Valid Loss {:.04f}\".format(\n",
    "        epoch + 1, config.epochs, train_loss, cur_lr, valid_loss))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af28af081fbc6591a0657d60a0d8fa83ec1369d1ecf4b5402213d8282a449a4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('intro2dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
